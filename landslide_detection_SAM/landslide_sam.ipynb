{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621cf2b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import timm\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "LANDSLIDE_IMG_DIR = PROJECT_ROOT / 'landslide' / 'image'\n",
    "LANDSLIDE_MASK_DIR = PROJECT_ROOT / 'landslide' / 'mask'\n",
    "NON_LANDSLIDE_IMG_DIR = PROJECT_ROOT / 'non-landslide' / 'image'\n",
    "IMG_EXTS = {'.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp'}\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_image(path, target_size=(256, 256)):\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    if img is None: raise RuntimeError(f\"Failed to read image: {path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    return img.astype(np.float32) / 255.0\n",
    "\n",
    "def load_mask(path, target_size=(256, 256)):\n",
    "    mask = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None: raise RuntimeError(f\"Failed to read mask: {path}\")\n",
    "    mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    return (mask > 0).astype(np.float32)\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class LandslideBijieDataset(Dataset):\n",
    "    def __init__(self, landslide_img_dir, landslide_mask_dir=None, \n",
    "                 non_landslide_img_dir=None, image_size=(256, 256), \n",
    "                 use_sam_guidance=True):\n",
    "        self.samples = []\n",
    "        self.image_size = image_size\n",
    "        self.use_sam_guidance = use_sam_guidance\n",
    "\n",
    "        if landslide_img_dir.exists():\n",
    "            for img_name in os.listdir(landslide_img_dir):\n",
    "                if Path(img_name).suffix.lower() in IMG_EXTS:\n",
    "                    mask_p = landslide_mask_dir / img_name if landslide_mask_dir else None\n",
    "                    self.samples.append({'img': landslide_img_dir/img_name, 'mask': mask_p, 'label': 1})\n",
    "\n",
    "        if non_landslide_img_dir and non_landslide_img_dir.exists():\n",
    "            for img_name in os.listdir(non_landslide_img_dir):\n",
    "                if Path(img_name).suffix.lower() in IMG_EXTS:\n",
    "                    self.samples.append({'img': non_landslide_img_dir/img_name, 'mask': None, 'label': 0})\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        img = load_image(item['img'], self.image_size)\n",
    "        mask = load_mask(item['mask'], self.image_size) if item['mask'] and item['mask'].exists() else np.zeros(self.image_size, dtype=np.float32)\n",
    "        \n",
    "        img_t = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        mask_t = torch.from_numpy(mask).unsqueeze(0)\n",
    "        \n",
    "        return {\n",
    "            'image': img_t,\n",
    "            'mask': mask_t,\n",
    "            'label': torch.tensor(item['label'], dtype=torch.float32),\n",
    "            'sam_guidance': mask_t.clone() if self.use_sam_guidance else torch.zeros_like(mask_t)\n",
    "        }\n",
    "\n",
    "# --- Model Architecture ---\n",
    "class SAMSwinHybrid(nn.Module):\n",
    "    def __init__(self, backbone_name='swin_tiny_patch4_window7_224', img_channels=3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=True, in_chans=img_channels, features_only=True, out_indices=(1, 2, 3))\n",
    "        feats = self.backbone.feature_info.channels()\n",
    "\n",
    "        self.seg_decoder = nn.Sequential(\n",
    "            nn.Conv2d(feats[-1], 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2), nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2), nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "            nn.Linear(feats[-1], 128), nn.ReLU(True), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, sam_guidance=None):\n",
    "        feats = self.backbone(x)\n",
    "        feat = feats[-1]\n",
    "        if sam_guidance is not None:\n",
    "            sam_resized = F.interpolate(sam_guidance, size=feat.shape[-2:], mode='bilinear', align_corners=False)\n",
    "            feat = feat * (1.0 + sam_resized)\n",
    "        return self.seg_decoder(feat), self.cls_head(feat).squeeze(1)\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = LandslideBijieDataset(LANDSLIDE_IMG_DIR, LANDSLIDE_MASK_DIR, NON_LANDSLIDE_IMG_DIR)\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "    \n",
    "    model = SAMSwinHybrid().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print(f\"Starting training on {DEVICE}...\")\n",
    "    # Training loop would go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
